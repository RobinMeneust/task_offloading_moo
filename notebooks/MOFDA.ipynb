{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Objective Flow Direction Algorithm (MOFDA) for Task Offloading\n",
    "\n",
    "This notebook implements the MOFDA algorithm for the task offloading problem based on the paper \"Leader selection based Multi-Objective Flow Direction Algorithm. (MOFDA): A novel approach for engineering design problems.\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T21:57:35.569902Z",
     "start_time": "2025-03-07T21:57:35.555223Z"
    }
   },
   "source": "# !uv pip install pymoo",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:03.059854Z",
     "start_time": "2025-03-05T22:39:03.049778Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from pymoo.core.algorithm import Algorithm\n",
    "from pymoo.core.population import Population\n",
    "# For newer pymoo versions use:\n",
    "try:\n",
    "    from pymoo.util.archive import Archive\n",
    "except ImportError:\n",
    "    # Fallback for older pymoo versions\n",
    "    try:\n",
    "        from pymoo.core.archive import Archive\n",
    "    except ImportError:\n",
    "        # Create a simple Archive class if not available\n",
    "        class Archive(Population):\n",
    "            def __init__(self, *args, **kwargs):\n",
    "                super().__init__(*args, **kwargs)\n",
    "\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.util.misc import find_duplicates\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.core.individual import Individual\n",
    "from src.task_offloading_moo.pymoo.problem import TaskOffloadingProblem\n",
    "from src.task_offloading_moo.pymoo.operators.repair import TaskOffloadingRepair\n",
    "from src.task_offloading_moo.pymoo.operators.sampling import TaskOffloadingSampling"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementing MOFDA\n",
    "\n",
    "First, we'll implement the Multi-Objective Flow Direction Algorithm based on the paper description."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:03.078926Z",
     "start_time": "2025-03-05T22:39:03.071490Z"
    }
   },
   "source": [
    "class MOFDAArchive:\n",
    "    \"\"\"Custom archive implementation for MOFDA algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, size=None):\n",
    "        self.size = size\n",
    "        self.data = Population()\n",
    "        self.grid = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def add(self, pop):\n",
    "        \"\"\"Add solutions to the archive and return the archive itself.\n",
    "        This method is needed for compatibility with pymoo's algorithm framework.\"\"\"\n",
    "        self.update(pop)\n",
    "        return self\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data.get(key) if len(self.data) > 0 else None\n",
    "    \n",
    "    def _accept(self, pop):\n",
    "        \"\"\"Accept only non-dominated solutions to the archive\"\"\"\n",
    "        # Safety check for empty populations\n",
    "        if pop is None or len(pop) == 0:\n",
    "            return np.array([], dtype=bool)\n",
    "            \n",
    "        # Get the population's objective values\n",
    "        F_pop = pop.get(\"F\")\n",
    "        \n",
    "        # If archive is empty, just do non-dominated sorting within the population\n",
    "        if len(self.data) == 0:\n",
    "            if len(pop) <= 1:\n",
    "                return np.full(len(pop), True)\n",
    "            else:\n",
    "                # Find non-dominated solutions in the population\n",
    "                fronts = NonDominatedSorting().do(F_pop, only_non_dominated_front=True)\n",
    "                # Create acceptance mask\n",
    "                accepted = np.zeros(len(pop), dtype=bool)\n",
    "                \n",
    "                # Handle both single integer and array cases\n",
    "                if isinstance(fronts[0], (int, np.integer)):\n",
    "                    accepted[fronts[0]] = True\n",
    "                else:\n",
    "                    for idx in fronts[0]:\n",
    "                        accepted[idx] = True\n",
    "                return accepted\n",
    "        \n",
    "        # If we have archive data, compare with current population\n",
    "        F_archive = self.data.get(\"F\")\n",
    "        \n",
    "        # Combine archive and population objectives for sorting\n",
    "        F_all = np.vstack([F_archive, F_pop])\n",
    "        \n",
    "        # Find non-dominated solutions across both sets\n",
    "        fronts = NonDominatedSorting().do(F_all, only_non_dominated_front=True)\n",
    "        \n",
    "        # Create acceptance mask for population solutions\n",
    "        accepted = np.zeros(len(pop), dtype=bool)\n",
    "        archive_size = len(F_archive)\n",
    "        \n",
    "        # Handle both single integer and array cases\n",
    "        if isinstance(fronts[0], (int, np.integer)):\n",
    "            if fronts[0] >= archive_size:\n",
    "                accepted[fronts[0] - archive_size] = True\n",
    "        else:\n",
    "            for idx in fronts[0]:\n",
    "                if idx >= archive_size:\n",
    "                    accepted[idx - archive_size] = True\n",
    "        \n",
    "        return accepted\n",
    "    \n",
    "    def update(self, pop):\n",
    "        if pop is None or len(pop) == 0:\n",
    "            return\n",
    "            \n",
    "        accept = self._accept(pop)\n",
    "        if np.any(accept):\n",
    "            accepted = pop[accept]\n",
    "            if len(self.data) == 0:\n",
    "                self.data = accepted\n",
    "            else:\n",
    "                self.data = Population.merge(self.data, accepted)\n",
    "            self._filter()\n",
    "    \n",
    "    def _filter(self):\n",
    "        if self.size is None or len(self.data) <= self.size:\n",
    "            return\n",
    "        \n",
    "        # Use grid-based crowding distance\n",
    "        F = self.data.get(\"F\")\n",
    "        n_dim = F.shape[1]\n",
    "        n_grid = max(2, int(np.ceil(self.size ** (1/n_dim))))\n",
    "        \n",
    "        grid_indices = np.zeros((len(F), n_dim), dtype=int)\n",
    "        for i in range(n_dim):\n",
    "            f_min, f_max = F[:, i].min(), F[:, i].max()\n",
    "            delta = (f_max - f_min) / n_grid if f_max > f_min else 1.0\n",
    "            grid_indices[:, i] = np.minimum(np.floor((F[:, i] - f_min) / delta), n_grid-1)\n",
    "        \n",
    "        # Count solutions in each cell\n",
    "        unique_cells, cell_counts = np.unique(grid_indices, axis=0, return_counts=True)\n",
    "        crowding = np.zeros(len(F))\n",
    "        for i, indices in enumerate(grid_indices):\n",
    "            idx = np.where((unique_cells == indices).all(axis=1))[0][0]\n",
    "            crowding[i] = cell_counts[idx]\n",
    "        \n",
    "        # Keep the least crowded solutions\n",
    "        I = np.argsort(crowding)[:self.size]\n",
    "        self.data = self.data[I]\n",
    "        \n",
    "        # Update grid information\n",
    "        self.grid = {'indices': grid_indices[I], 'counts': crowding[I]}\n",
    "    \n",
    "    def get_leader(self):\n",
    "        if len(self.data) == 0:\n",
    "            return None\n",
    "        \n",
    "        if self.grid is None:\n",
    "            return self.data[np.random.randint(len(self.data))]\n",
    "        \n",
    "        # Select from less crowded regions\n",
    "        probs = 1.0 / self.grid['counts']\n",
    "        probs = probs / np.sum(probs)\n",
    "        idx = np.random.choice(len(self.data), p=probs)\n",
    "        return self.data[idx]"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:03.093887Z",
     "start_time": "2025-03-05T22:39:03.078926Z"
    }
   },
   "source": [
    "from pymoo.util.display.multi import MultiObjectiveOutput\n",
    "\n",
    "class MOFDAOptimizer(Algorithm):\n",
    "    \"\"\"Multi-Objective Flow Direction Algorithm (MOFDA) for multi-objective optimization.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 pop_size=100,\n",
    "                 sampling=None,\n",
    "                 repair=None,\n",
    "                 archive_size=100,\n",
    "                 n_max_iters=100,\n",
    "                 w=0.4,        # weight factor for velocity control\n",
    "                 c1=2,         # control parameter for neighborhood radius\n",
    "                 c2=2,         # control parameter for flow movement\n",
    "                 beta=4,       # number of neighbors around each flow\n",
    "                 delta=0.5,    # mutation rate\n",
    "                 use_soft_repair=True,\n",
    "                 save_history=False,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(output=MultiObjectiveOutput(), **kwargs)\n",
    "        \n",
    "        self.pop_size = pop_size\n",
    "        self.sampling = sampling\n",
    "        self.repair = repair\n",
    "        self.n_max_iters = n_max_iters\n",
    "        self.archive_size = archive_size\n",
    "        self.w = w\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.beta = beta\n",
    "        self.delta = delta\n",
    "        self.use_soft_repair = use_soft_repair\n",
    "        self.save_history = save_history\n",
    "        \n",
    "        # Create archive without parameters first\n",
    "        self.archive = MOFDAArchive(size=archive_size)\n",
    "        # Then set size attribute separately\n",
    "        self.archive.size = archive_size\n",
    "        self.current_iter = 0\n",
    "\n",
    "    def copy(self, deep=False):\n",
    "        return copy.deepcopy(self) if deep else copy.copy(self)\n",
    "\n",
    "    def _initialize_infill(self):\n",
    "        \"\"\"Initialize the first population if it doesn't exist yet.\"\"\"\n",
    "        # Create initial population using the sampling method\n",
    "        if self.sampling is not None:\n",
    "            self.pop = self.sampling.do(self.problem, self.pop_size)\n",
    "        else:\n",
    "            # Use default random sampling as fallback\n",
    "            X = np.random.random((self.pop_size, self.problem.n_var))\n",
    "            # Scale to problem bounds\n",
    "            xl, xu = self.problem.xl, self.problem.xu\n",
    "            X = xl + X * (xu - xl)\n",
    "            # Create population\n",
    "            self.pop = Population.new(\"X\", X)\n",
    "        \n",
    "        # Evaluate the initial population\n",
    "        self.evaluator.eval(self.problem, self.pop)\n",
    "        \n",
    "        return self.pop\n",
    "\n",
    "    def _initialize_advance(self, infills=None, **kwargs):\n",
    "        # Add initial population to archive\n",
    "        self.archive.update(self.pop)\n",
    "\n",
    "    def _repair_solution(self, X):\n",
    "        \"\"\"Ensure solutions contain valid integer machine assignments.\"\"\"\n",
    "        if X is None:\n",
    "            return X\n",
    "            \n",
    "        # Make a copy to avoid modifying the original\n",
    "        X_repaired = X.copy()\n",
    "        \n",
    "        # Get problem bounds\n",
    "        xl = self.problem.xl\n",
    "        xu = self.problem.xu\n",
    "        \n",
    "        # Apply bounds and convert to integers\n",
    "        for i in range(len(X_repaired)):\n",
    "            # First round to nearest integers\n",
    "            X_repaired[i] = np.round(X_repaired[i])\n",
    "            \n",
    "            # Then ensure values are within bounds\n",
    "            X_repaired[i] = np.maximum(X_repaired[i], xl)\n",
    "            X_repaired[i] = np.minimum(X_repaired[i], xu)\n",
    "            \n",
    "            # Convert to integers explicitly\n",
    "            X_repaired[i] = X_repaired[i].astype(int)\n",
    "        \n",
    "        return X_repaired\n",
    "\n",
    "    def _infill(self):\n",
    "        # Create offspring using FDA operators\n",
    "        n_offsprings = self.pop_size\n",
    "        offsprings = np.empty(n_offsprings, dtype=object)\n",
    "        \n",
    "        # Get current population\n",
    "        X = self.pop.get(\"X\")\n",
    "        n_vars = X.shape[1]\n",
    "        \n",
    "        # Get leader from archive (best non-dominated solution)\n",
    "        leader = self.archive.get_leader()\n",
    "        leader_X = leader.get(\"X\") if leader is not None else None\n",
    "        \n",
    "        # For each individual in population\n",
    "        for i in range(n_offsprings):\n",
    "            # Current flow position\n",
    "            flow_X = X[i % len(X)].copy()\n",
    "            \n",
    "            # Generate neighbors for each flow\n",
    "            neighbors_X = np.empty((self.beta, n_vars))\n",
    "            for j in range(self.beta):\n",
    "                # Create neighbor using normal distribution around current flow\n",
    "                delta = np.random.randn(n_vars)\n",
    "                \n",
    "                # Calculate neighborhood radius\n",
    "                radius = delta * np.linalg.norm(leader_X - flow_X) if leader_X is not None else delta\n",
    "                \n",
    "                # Create neighbor\n",
    "                neighbors_X[j] = flow_X + radius\n",
    "            \n",
    "            # Evaluate neighbors\n",
    "                        # Fixed code using proper Population\n",
    "                        # In the _infill method of MOFDAOptimizer:\n",
    "            \n",
    "            # Before evaluation, make sure all machine assignments are proper integers\n",
    "            for j in range(len(neighbors_X)):\n",
    "                # Important: First convert to integer type\n",
    "                neighbors_X[j] = neighbors_X[j].astype(int)\n",
    "                \n",
    "                # Then use the problem's repair mechanism which knows about constraints\n",
    "                if self.use_soft_repair and hasattr(self.problem, 'soft_repair'):\n",
    "                    neighbors_X[j] = self.problem.soft_repair(flow_X, neighbors_X[j])\n",
    "                elif hasattr(self.problem, 'repair'):\n",
    "                    neighbors_X[j] = self.problem.repair(neighbors_X[j])\n",
    "                else:\n",
    "                    # Basic bounds repair as fallback\n",
    "                    xl, xu = self.problem.xl, self.problem.xu\n",
    "                    neighbors_X[j] = np.clip(neighbors_X[j], xl, xu).astype(int)\n",
    "                        # Inside your _infill method, after generating neighbors_X:\n",
    "            num_machines = self.problem.dataset_generator.get_num_machines()\n",
    "            for j in range(len(neighbors_X)):\n",
    "                # Round the solution and cast to integer\n",
    "                repaired = np.round(neighbors_X[j]).astype(int)\n",
    "                # Clip values to the valid range\n",
    "                repaired = np.clip(repaired, 0, num_machines - 1)\n",
    "                # (Optionally, apply your domain-specific repair if available)\n",
    "                if self.use_soft_repair and hasattr(self.problem, 'soft_repair'):\n",
    "                    repaired = self.problem.soft_repair(flow_X, repaired)\n",
    "                neighbors_X[j] = repaired\n",
    "            neighbors_X = neighbors_X.astype(int)\n",
    "            # Create population with repaired solutions\n",
    "            neighbors = Population.new(\"X\", neighbors_X)\n",
    "            \n",
    "            self.evaluator.eval(self.problem, neighbors)\n",
    "            \n",
    "            # Find best neighbor (using non-dominated sorting if multi-objective)\n",
    "            F_neighbors = np.array([n.get(\"F\") for n in neighbors])\n",
    "            F_current = self.pop[i].get(\"F\")\n",
    "            \n",
    "            # Check if any neighbor dominates current flow\n",
    "            dominated = False\n",
    "            best_neighbor_idx = 0\n",
    "            \n",
    "            for j in range(self.beta):\n",
    "                if self._dominates(F_neighbors[j], F_current):\n",
    "                    dominated = True\n",
    "                    best_neighbor_idx = j\n",
    "                    break\n",
    "            \n",
    "            # Update flow position\n",
    "            if dominated:\n",
    "                # Calculate flow velocity based on slope\n",
    "                slope = (flow_X - neighbors_X[best_neighbor_idx]) / np.linalg.norm(flow_X - neighbors_X[best_neighbor_idx])\n",
    "                velocity = np.random.random() * slope\n",
    "                \n",
    "                # Update flow position\n",
    "                new_X = flow_X + velocity\n",
    "            else:\n",
    "                # Sink filling process - randomly select another flow\n",
    "                random_idx = np.random.randint(self.pop_size)\n",
    "                \n",
    "                if random_idx == i:\n",
    "                    random_idx = (random_idx + 1) % self.pop_size\n",
    "                \n",
    "                random_flow = self.pop[random_idx]\n",
    "                \n",
    "                # Compare fitness\n",
    "                if self._dominates(random_flow.get(\"F\"), F_current):\n",
    "                    # Move towards the random flow\n",
    "                    new_X = flow_X + np.random.random() * (random_flow.get(\"X\") - flow_X)\n",
    "                elif leader_X is not None:\n",
    "                    # Move towards the leader\n",
    "                    new_X = flow_X + 2 * np.random.random() * (leader_X - flow_X)\n",
    "                else:\n",
    "                    # Apply mutation\n",
    "                    if np.random.random() < self.delta:\n",
    "                        new_X = flow_X + np.random.randn(n_vars) * 0.1\n",
    "                    else:\n",
    "                        new_X = flow_X\n",
    "            \n",
    "            # Create new individual\n",
    "            offsprings[i] = Individual(X=new_X)\n",
    "        \n",
    "        # Apply repair operator if necessary\n",
    "        if self.repair is not None:\n",
    "            offsprings = self.repair.do(self.problem, Population(offsprings), use_soft=self.use_soft_repair)\n",
    "        \n",
    "        return offsprings\n",
    "    \n",
    "    def _dominates(self, F1, F2):\n",
    "        \"\"\"Check if F1 dominates F2 (assuming minimization).\"\"\"\n",
    "        return np.all(F1 <= F2) and np.any(F1 < F2)\n",
    "\n",
    "    def _advance(self, infills=None, **kwargs):\n",
    "        # Update archive with evaluated offspring\n",
    "        self.archive.update(infills)\n",
    "        \n",
    "        # Select next population from combined previous population and offspring\n",
    "        self.pop = self._select(self.pop, infills)\n",
    "        \n",
    "        # Save algorithm state in history\n",
    "        if self.save_history and self.current_iter % 1 == 0:\n",
    "            self.history.append(self.copy(deep=True))\n",
    "            \n",
    "        self.current_iter += 1\n",
    "\n",
    "    def _select(self, pop, off):\n",
    "        # Combine parent and offspring population\n",
    "        merged = Population.merge(pop, off)\n",
    "        \n",
    "        # For selection, use non-dominated sorting\n",
    "        F = merged.get(\"F\")\n",
    "        \n",
    "        # Perform non-dominated sorting\n",
    "        fronts = NonDominatedSorting().do(F, n_stop_if_ranked=len(merged))\n",
    "        \n",
    "        # Prepare indices to be selected\n",
    "        n_remaining = self.pop_size\n",
    "        indices = []\n",
    "        \n",
    "        for front in fronts:\n",
    "            # If we can take the whole front, add it\n",
    "            if len(front) <= n_remaining:\n",
    "                indices.extend(front)\n",
    "                n_remaining -= len(front)\n",
    "            # Otherwise, select based on crowding distance\n",
    "            else:\n",
    "                # Calculate crowding distance for this front\n",
    "                crowding_of_front = self._calc_crowding_distance(F[front])\n",
    "                \n",
    "                # Sort by crowding distance (higher is better)\n",
    "                I = np.argsort(-crowding_of_front)\n",
    "                I = I[:n_remaining]\n",
    "                \n",
    "                # Add selected individuals from this front\n",
    "                indices.extend(front[I])\n",
    "                break\n",
    "                \n",
    "        # Create the population for next generation\n",
    "        return merged[indices]\n",
    "    \n",
    "    def _calc_crowding_distance(self, F):\n",
    "        n_points, n_obj = F.shape\n",
    "        \n",
    "        if n_points <= 2:\n",
    "            return np.full(n_points, np.inf)\n",
    "        \n",
    "        # Initialize crowding distance\n",
    "        crowding = np.zeros(n_points)\n",
    "        \n",
    "        # Calculate crowding distance for each objective\n",
    "        for i in range(n_obj):\n",
    "            # Sort by current objective\n",
    "            idx = np.argsort(F[:, i])\n",
    "            \n",
    "            # Set the boundary points to infinity\n",
    "            crowding[idx[0]] = np.inf\n",
    "            crowding[idx[-1]] = np.inf\n",
    "            \n",
    "            # Calculate crowding distance for the rest\n",
    "            f_min = F[idx[0], i]\n",
    "            f_max = F[idx[-1], i]\n",
    "            \n",
    "            if f_max > f_min:\n",
    "                # Add normalized distance to crowding\n",
    "                crowding[idx[1:-1]] += (F[idx[2:], i] - F[idx[:-2], i]) / (f_max - f_min)\n",
    "                \n",
    "        return crowding\n",
    "        \n",
    "    def _set_optimum(self, **kwargs):\n",
    "        \"\"\"Fix the optimum population to ensure it has valid X values\"\"\"\n",
    "        # Create a proper Population if needed\n",
    "        if len(self.archive.data) == 0:\n",
    "            # Handle empty archive case by using best from current population\n",
    "            self.opt = Population()\n",
    "            return\n",
    "            \n",
    "        # Create Population from archive data\n",
    "        self.opt = Population.create(self.archive.data)\n",
    "        \n",
    "        # Ensure X values are present and properly formatted\n",
    "        if self.opt.get(\"X\") is None or self.opt.get(\"X\").size == 0:\n",
    "            # Copy X values from the current population if missing\n",
    "            if len(self.pop) > 0 and self.pop.get(\"X\") is not None:\n",
    "                n_vars = self.pop.get(\"X\").shape[1]\n",
    "                self.opt.set(\"X\", np.zeros((len(self.opt), n_vars)))"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problem Setup\n",
    "\n",
    "Now let's set up the task offloading problem similar to the PUMA notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:03.123863Z",
     "start_time": "2025-03-05T22:39:03.097271Z"
    }
   },
   "source": [
    "pop_size = 100\n",
    "n_max_iters = 10\n",
    "\n",
    "num_cloud_machines = 30\n",
    "num_fog_machines = 20\n",
    "num_tasks = 500\n",
    "\n",
    "# Add this code above your algorithm definition\n",
    "from pymoo.core.termination import Termination\n",
    "\n",
    "class MOFDATermination(Termination):\n",
    "    def __init__(self, n_max_gen=100):\n",
    "        super().__init__()\n",
    "        self.n_max_gen = n_max_gen\n",
    "        \n",
    "    def _update(self, algorithm):\n",
    "        # Calculate progress as percentage of maximum generations\n",
    "        if algorithm.n_gen >= self.n_max_gen:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return algorithm.n_gen / self.n_max_gen\n",
    "\n",
    "algorithm = MOFDAOptimizer(\n",
    "    repair=TaskOffloadingRepair(),\n",
    "    use_soft_repair=True,\n",
    "    pop_size=pop_size,\n",
    "    sampling=TaskOffloadingSampling(),\n",
    "    n_max_iters=n_max_iters,\n",
    "    archive_size=100,\n",
    "    save_history=True,\n",
    "    w=0.4,\n",
    "    c1=2,\n",
    "    c2=2,\n",
    "    beta=4,\n",
    "    delta=0.5\n",
    ")\n",
    "\n",
    "problem = TaskOffloadingProblem(num_cloud_machines, num_fog_machines, num_tasks)"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:07.135567Z",
     "start_time": "2025-03-05T22:39:03.127996Z"
    }
   },
   "source": [
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=MOFDATermination(n_max_gen=n_max_iters),\n",
    "               seed=1,\n",
    "               verbose=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      100 |      1 |             - |             -\n",
      "     2 |      600 |      1 |  0.000000E+00 |             f\n",
      "     3 |     1100 |      1 |  0.000000E+00 |             f\n",
      "     4 |     1600 |      1 |  0.000000E+00 |             f\n",
      "     5 |     2100 |      1 |  0.000000E+00 |             f\n",
      "     6 |     2600 |      1 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproblem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m               \u001B[49m\u001B[43malgorithm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m               \u001B[49m\u001B[43mtermination\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMOFDATermination\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_max_gen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_max_iters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m               \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m               \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\CYTechNVME\\MOO\\task_offloading_moo\\.venv\\Lib\\site-packages\\pymoo\\optimize.py:67\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001B[0m\n\u001B[0;32m     64\u001B[0m     algorithm\u001B[38;5;241m.\u001B[39msetup(problem, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;66;03m# actually execute the algorithm\u001B[39;00m\n\u001B[1;32m---> 67\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43malgorithm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m# store the deep copied algorithm in the result object\u001B[39;00m\n\u001B[0;32m     70\u001B[0m res\u001B[38;5;241m.\u001B[39malgorithm \u001B[38;5;241m=\u001B[39m algorithm\n",
      "File \u001B[1;32mC:\\CYTechNVME\\MOO\\task_offloading_moo\\.venv\\Lib\\site-packages\\pymoo\\core\\algorithm.py:138\u001B[0m, in \u001B[0;36mAlgorithm.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_next():\n\u001B[1;32m--> 138\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult()\n",
      "File \u001B[1;32mC:\\CYTechNVME\\MOO\\task_offloading_moo\\.venv\\Lib\\site-packages\\pymoo\\core\\algorithm.py:159\u001B[0m, in \u001B[0;36mAlgorithm.next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m infills \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluator\u001B[38;5;241m.\u001B[39meval(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproblem, infills, algorithm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 159\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43minfills\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfills\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;66;03m# if the algorithm does not follow the infill-advance scheme just call advance\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance()\n",
      "File \u001B[1;32mC:\\CYTechNVME\\MOO\\task_offloading_moo\\.venv\\Lib\\site-packages\\pymoo\\core\\algorithm.py:225\u001B[0m, in \u001B[0;36mAlgorithm.advance\u001B[1;34m(self, infills, **kwargs)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_advance()\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    223\u001B[0m \n\u001B[0;32m    224\u001B[0m     \u001B[38;5;66;03m# call the implementation of the advance method - if the infill is not None\u001B[39;00m\n\u001B[1;32m--> 225\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_advance\u001B[49m\u001B[43m(\u001B[49m\u001B[43minfills\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfills\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    227\u001B[0m     \u001B[38;5;66;03m# always advance to the next iteration - except if the algorithm returns False\u001B[39;00m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m val:\n",
      "Cell \u001B[1;32mIn[76], line 226\u001B[0m, in \u001B[0;36mMOFDAOptimizer._advance\u001B[1;34m(self, infills, **kwargs)\u001B[0m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;66;03m# Save algorithm state in history\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_history \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_iter \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 226\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_iter \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[1;32mIn[76], line 43\u001B[0m, in \u001B[0;36mMOFDAOptimizer.copy\u001B[1;34m(self, deep)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcopy\u001B[39m(\u001B[38;5;28mself\u001B[39m, deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m deep \u001B[38;5;28;01melse\u001B[39;00m copy\u001B[38;5;241m.\u001B[39mcopy(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:162\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    160\u001B[0m                 y \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    161\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 162\u001B[0m                 y \u001B[38;5;241m=\u001B[39m \u001B[43m_reconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;66;03m# If is its own copy, don't memoize.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:259\u001B[0m, in \u001B[0;36m_reconstruct\u001B[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001B[0m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m deep:\n\u001B[1;32m--> 259\u001B[0m         state \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(y, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__setstate__\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    261\u001B[0m         y\u001B[38;5;241m.\u001B[39m__setstate__(state)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:136\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    134\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 136\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:221\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    219\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 221\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:136\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    134\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 136\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:196\u001B[0m, in \u001B[0;36m_deepcopy_list\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    194\u001B[0m append \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mappend\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m x:\n\u001B[1;32m--> 196\u001B[0m     append(\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:162\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    160\u001B[0m                 y \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    161\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 162\u001B[0m                 y \u001B[38;5;241m=\u001B[39m \u001B[43m_reconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;66;03m# If is its own copy, don't memoize.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:259\u001B[0m, in \u001B[0;36m_reconstruct\u001B[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001B[0m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m deep:\n\u001B[1;32m--> 259\u001B[0m         state \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(y, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__setstate__\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    261\u001B[0m         y\u001B[38;5;241m.\u001B[39m__setstate__(state)\n",
      "    \u001B[1;31m[... skipping similar frames: deepcopy at line 136 (1 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:221\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    219\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 221\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "    \u001B[1;31m[... skipping similar frames: deepcopy at line 136 (1 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:196\u001B[0m, in \u001B[0;36m_deepcopy_list\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    194\u001B[0m append \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mappend\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m x:\n\u001B[1;32m--> 196\u001B[0m     append(\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "    \u001B[1;31m[... skipping similar frames: deepcopy at line 136 (4 times), _deepcopy_dict at line 221 (2 times), _reconstruct at line 259 (2 times), deepcopy at line 162 (2 times), _deepcopy_list at line 196 (1 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:196\u001B[0m, in \u001B[0;36m_deepcopy_list\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    194\u001B[0m append \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mappend\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m x:\n\u001B[1;32m--> 196\u001B[0m     append(\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "    \u001B[1;31m[... skipping similar frames: _deepcopy_dict at line 221 (2 times), _reconstruct at line 259 (2 times), deepcopy at line 162 (2 times), deepcopy at line 136 (2 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:162\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    160\u001B[0m                 y \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    161\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 162\u001B[0m                 y \u001B[38;5;241m=\u001B[39m \u001B[43m_reconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;66;03m# If is its own copy, don't memoize.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:259\u001B[0m, in \u001B[0;36m_reconstruct\u001B[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001B[0m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m deep:\n\u001B[1;32m--> 259\u001B[0m         state \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(y, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__setstate__\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    261\u001B[0m         y\u001B[38;5;241m.\u001B[39m__setstate__(state)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:136\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    134\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 136\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:221\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    219\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 221\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.0-windows-x86_64-none\\Lib\\copy.py:143\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    141\u001B[0m copier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__deepcopy__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 143\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    145\u001B[0m     reductor \u001B[38;5;241m=\u001B[39m dispatch_table\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:07.217930100Z",
     "start_time": "2025-03-05T22:37:35.273631Z"
    }
   },
   "source": [
    "plot = Scatter(title=\"MOFDA\")\n",
    "plot.add(res.F)\n",
    "plot.axis_labels = problem.dataset_generator.get_objective_names()\n",
    "_ = plot.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Animation of Optimization Progress"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:07.217930100Z",
     "start_time": "2025-03-05T22:37:35.340809Z"
    }
   },
   "source": [
    "!pip install pyrecorder"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrecorder in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: opencv-python>=4.0.0.21 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrecorder) (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrecorder) (2.2.1)\n",
      "Requirement already satisfied: matplotlib>=3 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrecorder) (3.10.1)\n",
      "Requirement already satisfied: imageio in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyrecorder) (2.37.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (3.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (4.56.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (11.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3->pyrecorder) (1.4.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pyrecorder) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\robin\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T22:39:07.217930100Z",
     "start_time": "2025-03-05T22:37:36.716313Z"
    }
   },
   "source": [
    "from pyrecorder.recorder import Recorder\n",
    "from pyrecorder.writers.video import Video\n",
    "import os\n",
    "\n",
    "out_path = os.path.join(os.path.dirname(os.getcwd()), \"output\")\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "with Recorder(Video(os.path.join(out_path, \"mofda_video.mp4\"))) as rec:\n",
    "\n",
    "    # for each algorithm object in the history\n",
    "    for entry in res.history:\n",
    "        sc = Scatter(title=(\"Gen %s\" % entry.n_gen))\n",
    "        sc.add(entry.opt.get(\"F\"))\n",
    "        sc.add(entry.problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "        sc.do()\n",
    "\n",
    "        # record the current visualization to the video\n",
    "        rec.record()"
   ],
   "outputs": [],
   "execution_count": 60
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": {
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# Multi-Objective Flow Direction Algorithm (MOFDA) for Task Offloading\n",
     "\n",
     "This notebook implements the MOFDA algorithm for the task offloading problem based on the paper \"Leader selection based Multi-Objective Flow Direction Algorithm. (MOFDA): A novel approach for engineering design problems.\""
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "import numpy as np\n",
     "from pymoo.core.algorithm import Algorithm\n",
     "from pymoo.core.population import Population\n",
     "from pymoo.core.archive import Archive\n",
     "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
     "from pymoo.util.misc import find_duplicates\n",
     "from pymoo.util.function_loader import load_function\n",
     "from pymoo.util.randomized_argsort import randomized_argsort\n",
     "from pymoo.core.individual import Individual\n",
     "from pymoo.core.problem import Problem\n",
     "from pymoo.optimize import minimize\n",
     "from pymoo.visualization.scatter import Scatter\n",
     "\n",
     "from task_offloading_moo.pymoo.problem import TaskOffloadingProblem\n",
     "from task_offloading_moo.pymoo.operators.repair import TaskOffloadingRepair\n",
     "from task_offloading_moo.pymoo.operators.sampling import TaskOffloadingSampling"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 1. Implementing MOFDA\n",
     "\n",
     "First, we'll implement the Multi-Objective Flow Direction Algorithm based on the paper description."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "class MOFDAArchive(Archive):\n",
     "    \"\"\"Archive implementation for MOFDA algorithm to store non-dominated solutions.\"\"\"\n",
     "    \n",
     "    def __init__(self, size=None):\n",
     "        super().__init__()\n",
     "        self.size = size\n",
     "        self.grid = None  # Will store grid information\n",
     "\n",
     "    def _accept(self, pop, events=None):\n",
     "        # Only accept non-dominated solutions\n",
     "        if len(self.data) == 0:\n",
     "            return np.full(len(pop), True)\n",
     "        else:\n",
     "            # Get the objective space values from archive and population\n",
     "            F_archive = self.get(\"F\")\n",
     "            F_pop = pop.get(\"F\")\n",
     "            \n",
     "            # Combine archive and population for non-dominated sorting\n",
     "            F_all = np.vstack([F_archive, F_pop])\n",
     "            \n",
     "            # Do non-dominated sorting for all solutions\n",
     "            fronts = NonDominatedSorting().do(F_all, only_non_dominated_front=True)\n",
     "            \n",
     "            # Check which solutions from the population are in the first front\n",
     "            accepted = np.zeros(len(pop), dtype=bool)\n",
     "            for k in fronts[0]:\n",
     "                if k >= len(F_archive):\n",
     "                    accepted[k - len(F_archive)] = True\n",
     "                    \n",
     "            return accepted\n",
     "    \n",
     "    def _filter(self):\n",
     "        # If archive size is not limited, no filtering is necessary\n",
     "        if self.size is None or len(self.data) <= self.size:\n",
     "            return\n",
     "        \n",
     "        # Get the objective values\n",
     "        F = self.get(\"F\")\n",
     "        \n",
     "        # Create a grid for crowding distance calculation\n",
     "        n_dim = F.shape[1]\n",
     "        n_grid_per_dim = int(np.ceil(np.power(self.size, 1/n_dim)))\n",
     "        \n",
     "        # Calculate grid indices for each dimension\n",
     "        grid_indices = np.zeros((len(F), n_dim), dtype=int)\n",
     "        \n",
     "        for i in range(n_dim):\n",
     "            f_min, f_max = F[:, i].min(), F[:, i].max()\n",
     "            delta = (f_max - f_min) / n_grid_per_dim if f_max > f_min else 1.0\n",
     "            grid_indices[:, i] = np.floor((F[:, i] - f_min) / delta)\n",
     "            # Handle edge case\n",
     "            grid_indices[:, i] = np.minimum(grid_indices[:, i], n_grid_per_dim - 1)\n",
     "        \n",
     "        # Count solutions in each grid cell\n",
     "        unique_cells, cell_counts = np.unique(grid_indices, axis=0, return_counts=True)\n",
     "        \n",
     "        # Map each solution to its cell count (crowding measure)\n",
     "        crowding = np.zeros(len(F))\n",
     "        for i, indices in enumerate(grid_indices):\n",
     "            idx = np.where((unique_cells == indices).all(axis=1))[0][0]\n",
     "            crowding[i] = cell_counts[idx]\n",
     "        \n",
     "        # Sort by crowding (descending) and keep only the required size\n",
     "        I = np.argsort(-crowding)[:self.size]\n",
     "        self.data = self.data[I]\n",
     "        \n",
     "        # Store grid information for leader selection\n",
     "        self.grid = {'indices': grid_indices[I], 'counts': crowding[I]}\n",
     "        \n",
     "    def get_leader(self):\n",
     "        \"\"\"Select a leader from the archive using roulette wheel based on grid density.\"\"\"\n",
     "        if len(self.data) == 0:\n",
     "            return None\n",
     "        \n",
     "        if self.grid is None:\n",
     "            # If grid information is not available, select randomly\n",
     "            return self.data[np.random.randint(len(self.data))]\n",
     "        \n",
     "        # Calculate selection probability inversely proportional to grid density\n",
     "        probs = 1.0 / self.grid['counts']\n",
     "        probs = probs / np.sum(probs)  # Normalize\n",
     "        \n",
     "        # Select using roulette wheel\n",
     "        idx = np.random.choice(len(self.data), p=probs)\n",
     "        return self.data[idx]"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "class MOFDAOptimizer(Algorithm):\n",
     "    \"\"\"Multi-Objective Flow Direction Algorithm (MOFDA) for multi-objective optimization.\"\"\"\n",
     "    \n",
     "    def __init__(self,\n",
     "                 pop_size=100,\n",
     "                 sampling=None,\n",
     "                 repair=None,\n",
     "                 archive_size=100,\n",
     "                 n_max_iters=100,\n",
     "                 w=0.4,        # weight factor for velocity control\n",
     "                 c1=2,         # control parameter for neighborhood radius\n",
     "                 c2=2,         # control parameter for flow movement\n",
     "                 beta=4,       # number of neighbors around each flow\n",
     "                 delta=0.5,    # mutation rate\n",
     "                 use_soft_repair=True,\n",
     "                 save_history=False,\n",
     "                 **kwargs):\n",
     "        \n",
     "        super().__init__(**kwargs)\n",
     "        \n",
     "        self.pop_size = pop_size\n",
     "        self.sampling = sampling\n",
     "        self.repair = repair\n",
     "        self.n_max_iters = n_max_iters\n",
     "        self.archive_size = archive_size\n",
     "        self.w = w\n",
     "        self.c1 = c1\n",
     "        self.c2 = c2\n",
     "        self.beta = beta\n",
     "        self.delta = delta\n",
     "        self.use_soft_repair = use_soft_repair\n",
     "        self.save_history = save_history\n",
     "        \n",
     "        self.archive = MOFDAArchive(size=archive_size)\n",
     "        self.current_iter = 0\n",
     "\n",
     "    def _initialize_advance(self, infills=None, **kwargs):\n",
     "        # Add initial population to archive\n",
     "        self.archive.update(self.pop)\n",
     "\n",
     "    def _infill(self):\n",
     "        # Create offspring using FDA operators\n",
     "        n_offsprings = self.pop_size\n",
     "        offsprings = np.empty(n_offsprings, dtype=object)\n",
     "        \n",
     "        # Get current population\n",
     "        X = self.pop.get(\"X\")\n",
     "        n_vars = X.shape[1]\n",
     "        \n",
     "        # Get leader from archive (best non-dominated solution)\n",
     "        leader = self.archive.get_leader()\n",
     "        leader_X = leader.get(\"X\") if leader is not None else None\n",
     "        \n",
     "        # For each individual in population\n",
     "        for i in range(n_offsprings):\n",
     "            # Current flow position\n",
     "            flow_X = X[i].copy()\n",
     "            \n",
     "            # Generate neighbors for each flow\n",
     "            neighbors_X = np.empty((self.beta, n_vars))\n",
     "            for j in range(self.beta):\n",
     "                # Create neighbor using normal distribution around current flow\n",
     "                delta = np.random.randn(n_vars)\n",
     "                \n",
     "                # Calculate neighborhood radius\n",
     "                radius = delta * np.linalg.norm(best_X - flow_X) if leader_X is not None else delta\n",
     "                \n",
     "                # Create neighbor\n",
     "                neighbors_X[j] = flow_X + radius\n",
     "            \n",
     "            # Evaluate neighbors\n",
     "            neighbors = np.array([Individual(X=x) for x in neighbors_X])\n",
     "            self.evaluator.eval(self.problem, neighbors)\n",
     "            \n",
     "            # Find best neighbor (using non-dominated sorting if multi-objective)\n",
     "            F_neighbors = np.array([n.get(\"F\") for n in neighbors])\n",
     "            F_current = self.pop[i].get(\"F\")\n",
     "            \n",
     "            # Check if any neighbor dominates current flow\n",
     "            dominated = False\n",
     "            best_neighbor_idx = 0\n",
     "            \n",
     "            for j in range(self.beta):\n",
     "                if self._dominates(F_neighbors[j], F_current):\n",
     "                    dominated = True\n",
     "                    best_neighbor_idx = j\n",
     "                    break\n",
     "            \n",
     "            # Update flow position\n",
     "            if dominated:\n",
     "                # Calculate flow velocity based on slope\n",
     "                slope = (flow_X - neighbors_X[best_neighbor_idx]) / np.linalg.norm(flow_X - neighbors_X[best_neighbor_idx])\n",
     "                velocity = np.random.random() * slope\n",
     "                \n",
     "                # Update flow position\n",
     "                new_X = flow_X + velocity\n",
     "            else:\n",
     "                # Sink filling process - randomly select another flow\n",
     "                random_idx = np.random.randint(self.pop_size)\n",
     "                \n",
     "                if random_idx == i:\n",
     "                    random_idx = (random_idx + 1) % self.pop_size\n",
     "                \n",
     "                random_flow = self.pop[random_idx]\n",
     "                \n",
     "                # Compare fitness\n",
     "                if self._dominates(random_flow.get(\"F\"), F_current):\n",
     "                    # Move towards the random flow\n",
     "                    new_X = flow_X + np.random.random() * (random_flow.get(\"X\") - flow_X)\n",
     "                elif leader_X is not None:\n",
     "                    # Move towards the leader\n",
     "                    new_X = flow_X + 2 * np.random.random() * (leader_X - flow_X)\n",
     "                else:\n",
     "                    # Apply mutation\n",
     "                    if np.random.random() < self.delta:\n",
     "                        new_X = flow_X + np.random.randn(n_vars) * 0.1\n",
     "                    else:\n",
     "                        new_X = flow_X\n",
     "            \n",
     "            # Create new individual\n",
     "            offsprings[i] = Individual(X=new_X)\n",
     "        \n",
     "        # Apply repair operator if necessary\n",
     "        if self.repair is not None:\n",
     "            offsprings = self.repair.do(self.problem, Population(offsprings), use_soft=self.use_soft_repair)\n",
     "        \n",
     "        return offsprings\n",
     "    \n",
     "    def _dominates(self, F1, F2):\n",
     "        \"\"\"Check if F1 dominates F2 (assuming minimization).\"\"\"\n",
     "        return np.all(F1 <= F2) and np.any(F1 < F2)\n",
     "\n",
     "    def _advance(self, infills=None, **kwargs):\n",
     "        # Update archive with evaluated offspring\n",
     "        self.archive.update(infills)\n",
     "        \n",
     "        # Select next population from combined previous population and offspring\n",
     "        self.pop = self._select(self.pop, infills)\n",
     "        \n",
     "        # Save algorithm state in history\n",
     "        if self.save_history and self.current_iter % 1 == 0:\n",
     "            self.history.append(self.copy(deep=True))\n",
     "            \n",
     "        self.current_iter += 1\n",
     "\n",
     "    def _select(self, pop, off):\n",
     "        # Combine parent and offspring population\n",
     "        merged = Population.merge(pop, off)\n",
     "        \n",
     "        # For selection, use non-dominated sorting\n",
     "        F = merged.get(\"F\")\n",
     "        \n",
     "        # Perform non-dominated sorting\n",
     "        fronts = NonDominatedSorting().do(F, n_stop_if_ranked=len(merged))\n",
     "        \n",
     "        # Prepare indices to be selected\n",
     "        n_remaining = self.pop_size\n",
     "        indices = []\n",
     "        \n",
     "        for front in fronts:\n",
     "            # If we can take the whole front, add it\n",
     "            if len(front) <= n_remaining:\n",
     "                indices.extend(front)\n",
     "                n_remaining -= len(front)\n",
     "            # Otherwise, select based on crowding distance\n",
     "            else:\n",
     "                # Calculate crowding distance for this front\n",
     "                crowding_of_front = self._calc_crowding_distance(F[front])\n",
     "                \n",
     "                # Sort by crowding distance (higher is better)\n",
     "                I = np.argsort(-crowding_of_front)\n",
     "                I = I[:n_remaining]\n",
     "                \n",
     "                # Add selected individuals from this front\n",
     "                indices.extend(front[I])\n",
     "                break\n",
     "                \n",
     "        # Create the population for next generation\n",
     "        return merged[indices]\n",
     "    \n",
     "    def _calc_crowding_distance(self, F):\n",
     "        n_points, n_obj = F.shape\n",
     "        \n",
     "        if n_points <= 2:\n",
     "            return np.full(n_points, np.inf)\n",
     "        \n",
     "        # Initialize crowding distance\n",
     "        crowding = np.zeros(n_points)\n",
     "        \n",
     "        # Calculate crowding distance for each objective\n",
     "        for i in range(n_obj):\n",
     "            # Sort by current objective\n",
     "            idx = np.argsort(F[:, i])\n",
     "            \n",
     "            # Set the boundary points to infinity\n",
     "            crowding[idx[0]] = np.inf\n",
     "            crowding[idx[-1]] = np.inf\n",
     "            \n",
     "            # Calculate crowding distance for the rest\n",
     "            f_min = F[idx[0], i]\n",
     "            f_max = F[idx[-1], i]\n",
     "            \n",
     "            if f_max > f_min:\n",
     "                # Add normalized distance to crowding\n",
     "                crowding[idx[1:-1]] += (F[idx[2:], i] - F[idx[:-2], i]) / (f_max - f_min)\n",
     "                \n",
     "        return crowding\n",
     "        \n",
     "    def _set_optimum(self, **kwargs):\n",
     "        # The optimum is all non-dominated solutions in the archive\n",
     "        self.opt = self.archive.data"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 2. Problem Setup\n",
     "\n",
     "Now let's set up the task offloading problem similar to the PUMA notebook."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "pop_size = 100\n",
     "n_max_iters = 50\n",
     "\n",
     "num_cloud_machines = 30\n",
     "num_fog_machines = 20\n",
     "num_tasks = 500\n",
     "\n",
     "algorithm = MOFDAOptimizer(\n",
     "    repair=TaskOffloadingRepair(),\n",
     "    use_soft_repair=True,\n",
     "    pop_size=pop_size,\n",
     "    sampling=TaskOffloadingSampling(),\n",
     "    n_max_iters=n_max_iters,\n",
     "    archive_size=100,\n",
     "    save_history=True,\n",
     "    w=0.4,\n",
     "    c1=2,\n",
     "    c2=2,\n",
     "    beta=4,\n",
     "    delta=0.5\n",
     ")\n",
     "\n",
     "problem = TaskOffloadingProblem(num_cloud_machines, num_fog_machines, num_tasks)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 3. Run Optimization"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "res = minimize(problem,\n",
     "               algorithm,\n",
     "               seed=1,\n",
     "               verbose=True)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 4. Visualize Results"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "plot = Scatter(title=\"MOFDA\")\n",
     "plot.add(res.F)\n",
     "plot.axis_labels = problem.dataset_generator.get_objective_names()\n",
     "_ = plot.show()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 5. Create Animation of Optimization Progress"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "from pyrecorder.recorder import Recorder\n",
     "from pyrecorder.writers.video import Video\n",
     "import os\n",
     "\n",
     "out_path = os.path.join(os.path.dirname(os.getcwd()), \"output\")\n",
     "os.makedirs(out_path, exist_ok=True)\n",
     "with Recorder(Video(os.path.join(out_path, \"mofda_video.mp4\"))) as rec:\n",
     "\n",
     "    # for each algorithm object in the history\n",
     "    for entry in res.history:\n",
     "        sc = Scatter(title=(\"Gen %s\" % entry.n_gen))\n",
     "        sc.add(entry.opt.get(\"F\"))\n",
     "        sc.add(entry.problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
     "        sc.do()\n",
     "\n",
     "        # record the current visualization to the video\n",
     "        rec.record()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 6. Compare MOFDA and PUMA results\n",
     "\n",
     "To compare the performance of MOFDA against PUMA, we can load results from both algorithms and visualize them together."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "# You can uncomment and run this after executing both MOFDA and PUMA notebooks\n",
     "\n",
     "# import pickle\n",
     "# import os\n",
     "# \n",
     "# # Save MOFDA results\n",
     "# with open(os.path.join(out_path, 'mofda_results.pkl'), 'wb') as f:\n",
     "#     pickle.dump(res, f)\n",
     "#     \n",
     "# # Load PUMA results (assuming they're already saved)\n",
     "# puma_res = None\n",
     "# try:\n",
     "#     with open(os.path.join(out_path, 'puma_results.pkl'), 'rb') as f:\n",
     "#         puma_res = pickle.load(f)\n",
     "# except FileNotFoundError:\n",
     "#     print(\"PUMA results file not found. Run PUMA notebook first and save results.\")\n",
     "#     \n",
     "# # If PUMA results are loaded, compare with MOFDA\n",
     "# if puma_res is not None:\n",
     "#     plot = Scatter(title=\"MOFDA vs PUMA\")\n",
     "#     plot.add(res.F, label=\"MOFDA\")\n",
     "#     plot.add(puma_res.F, label=\"PUMA\")\n",
     "#     plot.axis_labels = problem.dataset_generator.get_objective_names()\n",
     "#     _ = plot.show()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 7. Analyze MOFDA Performance\n",
     "\n",
     "We can analyze the performance of MOFDA using various metrics like generational distance, spacing, maximum spread, and hypervolume."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
     "# Analyze the convergence and diversity metrics\n",
     "\n",
     "# from pymoo.indicators.gd import GD\n",
     "# from pymoo.indicators.igd import IGD\n",
     "# from pymoo.indicators.hv import HV\n",
     "# \n",
     "# # Get the Pareto front approximation\n",
     "# F = res.F\n",
     "# \n",
     "# # If the true Pareto front is available\n",
     "# pf = problem.pareto_front()\n",
     "# \n",
     "# if pf is not None:\n",
     "#     # Calculate Generational Distance\n",
     "#     gd = GD(pf)\n",
     "#     gd_value = gd.do(F)\n",
     "#     print(f\"Generational Distance: {gd_value}\")\n",
     "#     \n",
     "#     # Calculate Inverted Generational Distance\n",
     "#     igd = IGD(pf)\n",
     "#     igd_value = igd.do(F)\n",
     "#     print(f\"Inverted Generational Distance: {igd_value}\")\n",
     "#     \n",
     "# # Calculate Hypervolume (requires reference point)\n",
     "# ref_point = np.max(F, axis=0) * 1.1  # 10% larger than the maximum observed values\n",
     "# hv = HV(ref_point=ref_point)\n",
     "# hv_value = hv.do(F)\n",
     "# print(f\"Hypervolume: {hv_value}\")"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.10"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 }
}
